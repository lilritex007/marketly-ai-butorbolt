{"version":3,"file":"geminiService.js","sources":["../../src/services/geminiService.js"],"sourcesContent":["/**\n * Gemini AI Service - Frontend service for AI calls\n * All calls go through our backend proxy for security\n * The API key is stored on the server, NOT in the frontend\n */\n\n// Backend API URL - automatically detects if we're on the Railway server or localhost\nconst API_BASE = window.MARKETLY_CONFIG?.apiBase || \n  (window.location.hostname === 'localhost' \n    ? 'http://localhost:3001/api' \n    : 'https://marketly-ai-butorbolt-production.up.railway.app/api');\n\n/**\n * Generate text response from AI\n * @param {string} prompt - The prompt to send to AI\n * @param {object} options - Optional settings (temperature, maxTokens)\n * @returns {Promise<{success: boolean, text?: string, error?: string}>}\n */\nexport async function generateText(prompt, options = {}) {\n  const { temperature = 0.7, maxTokens = 500 } = options;\n  \n  console.log('[AI Service] Sending text generation request...');\n  \n  try {\n    const response = await fetch(`${API_BASE}/ai/generate`, {\n      method: 'POST',\n      headers: { \n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        prompt,\n        temperature,\n        maxTokens,\n      }),\n    });\n\n    const data = await response.json();\n    \n    if (!response.ok || !data.success) {\n      console.error('[AI Service] Error:', data.error);\n      return { \n        success: false, \n        error: data.error || `HTTP ${response.status}` \n      };\n    }\n\n    console.log('[AI Service] Success, response received');\n    return { success: true, text: data.text };\n\n  } catch (error) {\n    console.error('[AI Service] Network error:', error);\n    return { \n      success: false, \n      error: `Network error: ${error.message}` \n    };\n  }\n}\n\n/**\n * Analyze image with AI\n * @param {string} base64Image - Base64 encoded image (without data URL prefix)\n * @param {string} mimeType - Image MIME type (e.g., 'image/jpeg')\n * @param {string} prompt - The analysis prompt\n * @returns {Promise<{success: boolean, text?: string, error?: string}>}\n */\nexport async function analyzeImage(base64Image, mimeType, prompt) {\n  console.log('[AI Service] Sending image analysis request...');\n  \n  try {\n    const response = await fetch(`${API_BASE}/ai/analyze-image`, {\n      method: 'POST',\n      headers: { \n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        imageBase64: base64Image,\n        mimeType,\n        prompt,\n      }),\n    });\n\n    const data = await response.json();\n    \n    if (!response.ok || !data.success) {\n      console.error('[AI Service] Error:', data.error);\n      return { \n        success: false, \n        error: data.error || `HTTP ${response.status}` \n      };\n    }\n\n    console.log('[AI Service] Image analysis success');\n    return { success: true, text: data.text };\n\n  } catch (error) {\n    console.error('[AI Service] Network error:', error);\n    return { \n      success: false, \n      error: `Network error: ${error.message}` \n    };\n  }\n}\n\n/**\n * Test AI connection\n * @returns {Promise<{success: boolean, message?: string, error?: string}>}\n */\nexport async function testConnection() {\n  console.log('[AI Service] Testing connection...');\n  \n  try {\n    const response = await fetch(`${API_BASE}/ai/health`);\n    const data = await response.json();\n    \n    if (data.success) {\n      console.log('[AI Service] Connection OK:', data.message);\n      return { success: true, message: data.message };\n    } else {\n      console.error('[AI Service] Connection failed:', data.error);\n      return { success: false, error: data.error };\n    }\n\n  } catch (error) {\n    console.error('[AI Service] Connection test failed:', error);\n    return { \n      success: false, \n      error: `Cannot reach server: ${error.message}` \n    };\n  }\n}\n\nexport default {\n  generateText,\n  analyzeImage,\n  testConnection,\n};\n"],"names":["_a","API_BASE","generateText","prompt","options","temperature","maxTokens","response","data","error","analyzeImage","base64Image","mimeType"],"mappings":"AAAA,IAAAA,EAOA,MAAMC,IAAWD,EAAA,OAAO,kBAAP,YAAAA,EAAwB,WACtC,OAAO,SAAS,WAAa,YAC1B,4BACA,+DAQC,eAAeE,EAAaC,EAAQC,EAAU,GAAI,CACvD,KAAM,CAAE,YAAAC,EAAc,GAAK,UAAAC,EAAY,GAAG,EAAKF,EAE/C,QAAQ,IAAI,iDAAiD,EAE7D,GAAI,CACF,MAAMG,EAAW,MAAM,MAAM,GAAGN,CAAQ,eAAgB,CACtD,OAAQ,OACR,QAAS,CACP,eAAgB,kBACxB,EACM,KAAM,KAAK,UAAU,CACnB,OAAAE,EACA,YAAAE,EACA,UAAAC,CACR,CAAO,CACP,CAAK,EAEKE,EAAO,MAAMD,EAAS,KAAI,EAEhC,MAAI,CAACA,EAAS,IAAM,CAACC,EAAK,SACxB,QAAQ,MAAM,sBAAuBA,EAAK,KAAK,EACxC,CACL,QAAS,GACT,MAAOA,EAAK,OAAS,QAAQD,EAAS,MAAM,EACpD,IAGI,QAAQ,IAAI,yCAAyC,EAC9C,CAAE,QAAS,GAAM,KAAMC,EAAK,IAAI,EAEzC,OAASC,EAAO,CACd,eAAQ,MAAM,8BAA+BA,CAAK,EAC3C,CACL,QAAS,GACT,MAAO,kBAAkBA,EAAM,OAAO,EAC5C,CACE,CACF,CASO,eAAeC,EAAaC,EAAaC,EAAUT,EAAQ,CAChE,QAAQ,IAAI,gDAAgD,EAE5D,GAAI,CACF,MAAMI,EAAW,MAAM,MAAM,GAAGN,CAAQ,oBAAqB,CAC3D,OAAQ,OACR,QAAS,CACP,eAAgB,kBACxB,EACM,KAAM,KAAK,UAAU,CACnB,YAAaU,EACb,SAAAC,EACA,OAAAT,CACR,CAAO,CACP,CAAK,EAEKK,EAAO,MAAMD,EAAS,KAAI,EAEhC,MAAI,CAACA,EAAS,IAAM,CAACC,EAAK,SACxB,QAAQ,MAAM,sBAAuBA,EAAK,KAAK,EACxC,CACL,QAAS,GACT,MAAOA,EAAK,OAAS,QAAQD,EAAS,MAAM,EACpD,IAGI,QAAQ,IAAI,qCAAqC,EAC1C,CAAE,QAAS,GAAM,KAAMC,EAAK,IAAI,EAEzC,OAASC,EAAO,CACd,eAAQ,MAAM,8BAA+BA,CAAK,EAC3C,CACL,QAAS,GACT,MAAO,kBAAkBA,EAAM,OAAO,EAC5C,CACE,CACF"}